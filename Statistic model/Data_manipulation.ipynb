{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0e11806-f115-4c58-901c-e0df970c90ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1df44313-3c0f-4200-a13e-b9589a4a9026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For scaling down the data\n",
    "\n",
    "def scale_data(df):\n",
    "    \"\"\"\n",
    "    Scales the columns of the given DataFrame using MinMaxScaler, excluding the specified columns.\n",
    "\n",
    "    :param df: pandas DataFrame containing the data to be scaled\n",
    "    :param exclude_columns: list of columns to exclude from scaling\n",
    "    :return: scaled DataFrame, scaler object\n",
    "    \"\"\"\n",
    "    exclude_col = ['Date']\n",
    "    columns_to_scale = [col for col in df.columns if col not in exclude_col]\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    df_scaled = df.copy()\n",
    "    df_scaled[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n",
    "    return df_scaled, scaler\n",
    "\n",
    "\n",
    "def inverse_scale_data(scaled_df, scaler):\n",
    "    \"\"\"\n",
    "    Inversely scales the columns of the given scaled DataFrame using the provided scaler, excluding the specified columns.\n",
    "\n",
    "    :param scaled_df: pandas DataFrame containing the scaled data\n",
    "    :param scaler: scaler object used for scaling\n",
    "    :param exclude_columns: list of columns to exclude from inverse scaling\n",
    "    :return: original DataFrame\n",
    "    \"\"\"\n",
    "    exclude_col=['Date']\n",
    "    columns_to_inverse_scale = [col for col in scaled_df.columns if col not in exclude_col]\n",
    "    df_original = scaled_df.copy()\n",
    "    df_original[columns_to_inverse_scale] = scaler.inverse_transform(scaled_df[columns_to_inverse_scale])\n",
    "    \n",
    "    return df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fddf7ead-b529-457a-913c-6dc706d4acfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "NIFTY = pd.read_csv('D:/UFG/Data collection/NIFTY.csv')\n",
    "NIFTY['Date']= pd.to_datetime(NIFTY['Date'], format='%Y-%m-%d')\n",
    "\n",
    "scaled_data, scaler = scale_data(NIFTY)\n",
    "#original_data = inverse_scale_data(scaled_data, scaler, exclude_col=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "088b34ae-5d26-4a59-9bdf-393f5b33b9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBOV = pd.read_csv('D:/UFG/Data collection/IBOV.csv')\n",
    "# IBOV['Date']= pd.to_datetime(IBOV['Date'], format='%Y-%m-%d')\n",
    "\n",
    "# scaled_data, scaler = scale_data(IBOV, exclude_col=['Date'])\n",
    "#original_data = inverse_scale_data(scaled_data, scaler, exclude_col=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bbf6f88-6bd7-4128-9f56-7b0ed9e9c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(14, 7))\n",
    "# plt.plot(scaled_data['Date'], scaled_data['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9ad9842-23e1-4520-ad85-f15256249551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Function to transform the original time series to stationary series\n",
    "def transform_to_stationary(df, period=14):\n",
    "    df_copy = df.copy()  # Make a copy to avoid modifying the original DataFrame\n",
    "    df_copy.set_index('Date', inplace=True)\n",
    "\n",
    "    # For Volume values\n",
    "    df_copy = df_copy.interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
    "    column_names = df_copy.columns\n",
    "    \n",
    "    residuals_dict = {}\n",
    "    trend_dict = {}\n",
    "    seasonal_dict = {}\n",
    "    decomposition_results = {}\n",
    "    \n",
    "    for column_name in column_names:\n",
    "        # Perform seasonal decomposition with an additive model\n",
    "        result = seasonal_decompose(df_copy[column_name], model='additive', period=period)\n",
    "        \n",
    "        # Extract components\n",
    "        residuals = result.resid.dropna()  # Drop NaNs that appear due to the decomposition process\n",
    "        trend = result.trend.dropna()\n",
    "        seasonal = result.seasonal.dropna()\n",
    "        \n",
    "        # Store components in dictionaries\n",
    "        residuals_dict[column_name] = residuals\n",
    "        trend_dict[column_name] = trend\n",
    "        seasonal_dict[column_name] = seasonal\n",
    "        decomposition_results[column_name] = result\n",
    "    \n",
    "    # Create DataFrames from dictionaries\n",
    "    df_residuals = pd.DataFrame(residuals_dict)\n",
    "    df_residuals.index.name = 'Date'\n",
    "    df_trend = pd.DataFrame(trend_dict)\n",
    "    df_trend.index.name = 'Date'\n",
    "    df_seasonal = pd.DataFrame(seasonal_dict)\n",
    "    df_seasonal.index.name = 'Date'\n",
    "    \n",
    "    return df_residuals, df_trend, df_seasonal, decomposition_results\n",
    "\n",
    "# Function to invert the transformation\n",
    "def inverse_transform(df_residuals, df_trend, df_seasonal, decomposition_results):\n",
    "    reconstructed_dict = {}\n",
    "    \n",
    "    for column_name in df_residuals.columns:\n",
    "        # Align indices\n",
    "        residuals = df_residuals[column_name]\n",
    "        trend = df_trend[column_name]\n",
    "        seasonal = df_seasonal[column_name]\n",
    "\n",
    "        # Reconstruct the original time series\n",
    "        reconstructed = residuals + trend + seasonal\n",
    "        reconstructed_dict[column_name] = reconstructed\n",
    "    \n",
    "    # Create a DataFrame from reconstructed dictionary\n",
    "    df_reconstructed = pd.DataFrame(reconstructed_dict)\n",
    "    df_reconstructed.index.name = 'Date'\n",
    "    \n",
    "    return df_reconstructed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b7869f4-617b-464f-bd41-214362940873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the original time series to stationary series\n",
    "df_residuals, df_trend, df_seasonal, decomposition_results = transform_to_stationary(scaled_data, period=14)\n",
    "\n",
    "# Reconstruct the original time series from residuals\n",
    "df_reconstructed = inverse_transform(df_residuals, df_trend, df_seasonal, decomposition_results)\n",
    "\n",
    "# Display the first few rows of the original, residuals, trend, seasonal, and reconstructed data\n",
    "\n",
    "# print(\"Original Data:\")\n",
    "# print(scaled_data.head())\n",
    "# print(\"\\nResiduals Data:\")\n",
    "# print(df_residuals.head())\n",
    "# print(\"\\nTrend Data:\")\n",
    "# print(df_trend.head())\n",
    "# print(\"\\nSeasonal Data:\")\n",
    "# print(df_seasonal.head())\n",
    "# print(\"\\nReconstructed Data:\")\n",
    "# print(df_reconstructed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7076afdb-d9d9-4367-af07-ced6def97038",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_residuals['Close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee55a349-4d8b-4671-9498-a5f39f56f2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADF test\n",
    "\n",
    "def adf_test(df, exclude_columns=[]):\n",
    "    \"\"\"\n",
    "    Performs the Augmented Dickey-Fuller (ADF) test on the specified columns in the DataFrame.\n",
    "\n",
    "    :param df: pandas DataFrame containing the data\n",
    "    :param exclude_columns: list of columns to exclude from ADF test\n",
    "    :return: DataFrame with ADF test results\n",
    "    \"\"\"\n",
    "    adf_results = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        result = adfuller(df[col].dropna())\n",
    "        adf_results.append({\n",
    "            'Column': col,\n",
    "            'ADF Statistic': result[0],\n",
    "            'p-value': format(result[1], \".5f\"),\n",
    "            'Used Lag': result[2],\n",
    "            'Number of Observations': result[3],\n",
    "            #'Critical Values': result[4],\n",
    "            'Stationary': result[1] < 0.05  # If p-value < 0.05, the series is stationary\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(adf_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3ee36a2-786e-4d13-a430-eff2016b6cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adf_results = adf_test(df_residuals)\n",
    "# adf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8572783-b692-415e-b5b2-7e67a42134f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d023472e-1f40-42a3-90f4-6fd86b1eb5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
